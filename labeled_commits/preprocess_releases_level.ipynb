{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_LINKS = {\n",
    "    \"abinit\": {\n",
    "        \"url\": \"https://github.com/abinit/abinit\",\n",
    "        \"lang\": \"fortran\"\n",
    "    },\n",
    "    \"mdanalysis\": {\n",
    "        \"url\": \"https://github.com/MDAnalysis/mdanalysis\",\n",
    "        \"lang\": \"python\"\n",
    "    },\n",
    "    \"libmesh\": {\n",
    "        \"url\": \"https://github.com/libMesh/libmesh\",\n",
    "        \"lang\": \"C\"\n",
    "    },\n",
    "    \"lammps\": {\n",
    "        \"url\": \"https://github.com/lammps/lammps\",\n",
    "        \"lang\": \"C\"\n",
    "    },\n",
    "    \"amber\": {\n",
    "        \"url\": \"https://github.com/Amber-MD\",\n",
    "        \"lang\": \"C\"\n",
    "    },\n",
    "    \"hoomd\": {\n",
    "        \"url\": \"https://github.com/joaander/hoomd-blue/tree/master/hoomd\",\n",
    "        \"lang\": \"C\"\n",
    "    },\n",
    "    \"pcmsolver\": {\n",
    "        \"url\": \"https://github.com/PCMSolver/pcmsolver\",\n",
    "        \"lang\": \"C\"\n",
    "    },\n",
    "    \"rmg-py\": {\n",
    "        \"url\": \"https://github.com/ReactionMechanismGenerator/RMG-Py\",\n",
    "        \"lang\": \"python\"\n",
    "    },\n",
    "    \"xenon\": {\n",
    "        \"url\": \"https://github.com/NLeSC/Xenon\",\n",
    "        \"lang\": \"Java\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/huyqt7/Projects/PhD/data-collection/labeled_commits\n"
     ]
    }
   ],
   "source": [
    "import os, sys, shlex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pdb import set_trace\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import dateutil\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "main_path = os.getcwd()\n",
    "print(main_path)\n",
    "p_df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abinit\n",
      "mdanalysis\n",
      "libmesh\n",
      "lammps\n",
      "amber\n",
      "hoomd\n",
      "pcmsolver\n",
      "rmg-py\n",
      "xenon\n"
     ]
    }
   ],
   "source": [
    "import subprocess as sp\n",
    "\n",
    "for p in REPO_LINKS.keys():\n",
    "    commits_dir = main_path + \"/preprocessed_commits/\" + p\n",
    "    files = [filename for filename in os.listdir(commits_dir) if filename.endswith(\".csv\")]\n",
    "    files = sorted(files)\n",
    "    dfs = []\n",
    "    for i in range(len(files)):\n",
    "        df = pd.read_csv(commits_dir + \"/\" + files[i])\n",
    "        if i == 0:\n",
    "            dfs = [df['hash'].iloc[0], df['hash'].iloc[-1]]\n",
    "        else:\n",
    "            dfs.append(df['hash'].iloc[-1])\n",
    "    print(p)\n",
    "    project_path = \"/home/huyqt7/Projects/PhD/eager/data/projects/%s/\" % p\n",
    "    os.chdir(project_path)\n",
    "    re_commits = []\n",
    "    for index in range(len(dfs)):\n",
    "        commit_cmd = \"git reset --hard {}\".format(dfs[index])\n",
    "        sp.call(commit_cmd, shell=True)\n",
    "        path = \"/home/huyqt7/Projects/PhD/data-collection/labeled_commits/release_level/%s/%s_%s.udb\" % (p, p, index) \n",
    "        if REPO_LINKS[p][\"lang\"] == \"fortran\":\n",
    "            cmd = \"und create -db {} -languages Fortran add {}\".format(str(path), str(project_path))\n",
    "            sp.call(cmd, shell=True)\n",
    "            cmd = \"und -db {} settings -FileTypes .F90=Fortran .F77=Fortran .F03=Fortran .F95=Fortran .F=Fortran\".format(str(path))\n",
    "            sp.call(cmd, shell=True)\n",
    "            cmd = \"und -db {} analyze -all\".format(str(path))\n",
    "        elif REPO_LINKS[p][\"lang\"] == \"python\":\n",
    "            cmd = \"und create -languages python add {} analyze {}\".format(\n",
    "                str(project_path), str(path))\n",
    "        elif REPO_LINKS[p][\"lang\"] == \"C\":\n",
    "            cmd = \"und create -languages C++ add {} analyze {}\".format(\n",
    "                str(project_path), str(path))\n",
    "        elif REPO_LINKS[p][\"lang\"] == \"Java\":\n",
    "            cmd = \"und create -languages Java add {} analyze {}\".format(\n",
    "                str(project_path), str(path))\n",
    "        sp.call(cmd, shell=True)\n",
    "        #print(commit_cmd, cmd, dfs[index], p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import understand as und\n",
    "for p in ['abinit']:\n",
    "    commits_dir = main_path + \"/release_level/\" + p\n",
    "    files = [filename for filename in os.listdir(commits_dir) if filename.endswith(\".udb\")]\n",
    "    no_files = len(files)\n",
    "    for i in range(no_files):\n",
    "        u_fname = \"%s/release_level/%s/%s_%s.udb\" % (main_path, p, p, i)\n",
    "        m_fname = \"%s/release_level/%s/%s_%s_file_metrics.csv\" % (main_path, p, p, i)\n",
    "        #print(u_fname)\n",
    "        db = und.open(u_fname)\n",
    "        metrics_dataframe = pd.DataFrame()\n",
    "        for f in db.ents(\"File\"):\n",
    "            metrics = f.metric(f.metrics())\n",
    "            metrics[\"File\"] = f.name()\n",
    "            metrics[\"Bugs\"] = 0\n",
    "            metrics_dataframe = metrics_dataframe.append(pd.Series(metrics), ignore_index=True)\n",
    "        columns_order = ['File'] + [a for a in metrics_dataframe.columns if a not in ['File', 'Bugs']] + ['Bugs']\n",
    "        metrics_dataframe = metrics_dataframe.reindex(columns=(columns_order))\n",
    "        metrics_dataframe = metrics_dataframe.drop_duplicates(subset='File', keep=\"last\").reset_index()\n",
    "        metrics_dataframe = metrics_dataframe.dropna()\n",
    "        metrics_dataframe.to_csv(m_fname, index=False)\n",
    "        db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _os_cmd(cmd, verbose=False):\n",
    "        \"\"\"\n",
    "        Run a command on the shell\n",
    "        Parameters\n",
    "        ----------\n",
    "        cmd: str\n",
    "            A command to run.\n",
    "        \"\"\"\n",
    "        cmd = shlex.split(cmd)\n",
    "        with sp.Popen(cmd, stdout=sp.PIPE, stderr=sp.DEVNULL) as p:\n",
    "            out, err = p.communicate()\n",
    "\n",
    "        if verbose:\n",
    "            print(out)\n",
    "            print(err)\n",
    "        return out, err\n",
    "\n",
    "def _files_changed_in_git_diff(hash_1, hash_2, p):\n",
    "        \"\"\"\n",
    "        Get a list of all the files changed between two hashes\n",
    "        Parameters\n",
    "        ----------\n",
    "        hash_1 : str\n",
    "            Commit hash 1.\n",
    "        hash_2 : bool\n",
    "            Commit hash 2.\n",
    "        Returns\n",
    "        -------\n",
    "        List[str]:\n",
    "            A list of all files changed. For simplicity we only include *.py\n",
    "            *.F90, *.c, *.cpp, *.java.\n",
    "        \"\"\"\n",
    "        project_path = \"/home/huyqt7/Projects/PhD/eager/data/projects/%s/\" % p\n",
    "        os.chdir(project_path)\n",
    "        sp.call(\"git reset --hard master\", shell=True)\n",
    "        out, __ = _os_cmd(\"git diff {}..{} --name-only\".format(hash_1, hash_2))\n",
    "        files_changed = []\n",
    "        for f in out.splitlines():\n",
    "            if f and \"__init__.py\" not in str(f):\n",
    "                type_f = str(f)[2:-1].split(\".\")\n",
    "                #print(str(f), type_f)\n",
    "                if type_f:\n",
    "                    if type_f[-1] in set([\"c\", \"cc\", \"cxx\", \"C\", \"cpp\", \"CPP\", \"h\", \"H\", \n",
    "                                   \"f90\", \"f\", \"f77\", \"f03\", \"f95\", \"for\", \"ftn\",\n",
    "                                   \"F90\", \"F\", \"F77\", \"F03\", \"F95\", \"For\", \"Ftn\", \n",
    "                                   \"py\", \"java\"]):\n",
    "                        file_name = str(f)\n",
    "                        #print(file_name)\n",
    "                        if type_f[-1][0] == \"F\":\n",
    "                            file_name[-4] == \"f\"\n",
    "                            files_changed.append(Path(file_name).name[:-1])\n",
    "                        else:\n",
    "                            files_changed.append(Path(file_name).name[:-1])\n",
    "                \n",
    "\n",
    "        # A work around for FORTRAN file extensions.\n",
    "        #if REPO_LINKS[p][\"lang\"] == \"fortran\":\n",
    "        #    files_changed = list(map(lambda x: x[:-4]+\".f90\", files_changed))\n",
    "        return files_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdanalysis /home/huyqt7/Projects/PhD/data-collection/labeled_commits\n",
      "8 190, 7 74, 6 68, 5 70, 4 72, 3 100, 2 97, 1 95, \n",
      "libmesh /home/huyqt7/Projects/PhD/data-collection/labeled_commits\n",
      "7 165, 6 129, 5 159, 4 199, 3 235, 2 236, 1 236, \n",
      "lammps /home/huyqt7/Projects/PhD/data-collection/labeled_commits\n",
      "8 132, 7 98, 6 114, 5 94, 4 88, 3 44, 2 22, 1 5, \n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "import subprocess as sp\n",
    "for p in ['mdanalysis', 'libmesh', 'lammps']:\n",
    "    print(p, main_path)\n",
    "    commits_dir = main_path + \"/preprocessed_commits/\" + p\n",
    "    files = [filename for filename in os.listdir(commits_dir) if filename.endswith(\".csv\")]\n",
    "    no_versions = len(files)\n",
    "    files_changed = [] \n",
    "    for index in range(no_versions, 0, -1):\n",
    "        c_fname = \"%s/preprocessed_commits/%s/%s_%s.csv\" % (main_path, p, p, index)\n",
    "        df_commits = pd.read_csv(c_fname, index_col=None)\n",
    "        fixed_bugs_indices = df_commits[df_commits['fastread_buggy'] == 1].index.values.tolist()\n",
    "        fixed_bugs_indices = [idx for idx in fixed_bugs_indices if idx > 1]\n",
    "        previous_bugs_indices = [idx-1 for idx in fixed_bugs_indices]\n",
    "        fixed_bugs = df_commits.loc[fixed_bugs_indices]['hash'].values\n",
    "        previous_bugs = df_commits.loc[previous_bugs_indices]['hash'].values\n",
    "        m_fname = \"%s/release_level/%s/%s_%s_file_metrics.csv\" % (main_path, p, p, index-1)\n",
    "        df_metrics = pd.read_csv(m_fname)\n",
    "        df_metrics['fastread_bugs'] = [0]*df_metrics.shape[0]\n",
    "        print(index, len(fixed_bugs_indices), end=\", \")\n",
    "        #df_metrics['Bugs'] = [0] * df_metrics.shape[0]\n",
    "        for hash_id, prev_id in zip(fixed_bugs, previous_bugs):\n",
    "            if not files_changed:\n",
    "                files_changed = _files_changed_in_git_diff(prev_id, hash_id, p)\n",
    "            else:\n",
    "                files_changed.extend(_files_changed_in_git_diff(prev_id, hash_id, p))\n",
    "            #print(files_changed)\n",
    "        for changed_item in files_changed:\n",
    "            changed_i_exist = list(df_metrics[df_metrics['File'] == changed_item].index)\n",
    "            if changed_i_exist:\n",
    "                df_metrics.loc[changed_i_exist, 'fastread_bugs'] += 1\n",
    "        df_metrics.to_csv(m_fname[:-4] + \"_1.csv\", index=False)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdanalysis /home/huyqt7/Projects/PhD/data-collection/labeled_commits\n",
      "352 352\n",
      "339 339\n",
      "392 392\n",
      "355 355\n",
      "426 426\n",
      "429 429\n",
      "403 403\n",
      "648 648\n",
      "libmesh /home/huyqt7/Projects/PhD/data-collection/labeled_commits\n",
      "1125 1125\n",
      "1326 1326\n",
      "1339 1339\n",
      "947 947\n",
      "1062 1062\n",
      "983 983\n",
      "1897 1897\n",
      "lammps /home/huyqt7/Projects/PhD/data-collection/labeled_commits\n",
      "807 807\n",
      "883 883\n",
      "914 914\n",
      "1180 1180\n",
      "855 855\n",
      "754 754\n",
      "837 837\n",
      "1284 1284\n"
     ]
    }
   ],
   "source": [
    "for p in ['mdanalysis', 'libmesh', 'lammps']:\n",
    "    print(p, main_path)\n",
    "    commits_dir = main_path + \"/preprocessed_commits/\" + p\n",
    "    commits_fs = [filename for filename in os.listdir(commits_dir) if filename.endswith(\".csv\")]\n",
    "    commits_fs = sorted(commits_fs)\n",
    "    fr_df = pd.read_csv(main_path + \"/fastread/\" + p + \"_fast_labeled.csv\")\n",
    "    fr_df['fr_labels'] = pd.Series(np.where(fr_df.code == 'yes', 1, 0), fr_df.index)\n",
    "    for f in commits_fs:\n",
    "        df = pd.read_csv(commits_dir + \"/\" + f, index_col=None)\n",
    "        human_labels = [0] * df.shape[0]\n",
    "        for index, row in df.iterrows():\n",
    "            h = str(row['hash'])\n",
    "            if len(h) > 7:\n",
    "                h = h[:7]\n",
    "            val = fr_df[fr_df['Document Title'].str.startswith(h)]\n",
    "            if not val.empty:\n",
    "                for i, row in val.iterrows():\n",
    "                    if str(row['Document Title'])[-2:] != \".0\":            \n",
    "                        human_labels[index] = val['fr_labels'].values.tolist()[-1]\n",
    "        print(len(human_labels), df['fastread_buggy'].shape[0]) \n",
    "        df['fastread_buggy'] = human_labels\n",
    "        df.to_csv(commits_dir + \"/\" + f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0, 1, 2, 3, 4]\n",
    "a[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
